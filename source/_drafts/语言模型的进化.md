---
author: 陈英发 Yingfa Chen
title: 语言模型的进化
date: 2024-02-01 17:51:30
categories:
tags:
- language modeling
- language models
- llm
- transformer
- nlp
- rnn
- deep learning
- machine learning
- research
- ai
draft: true
---
<style>
section {
  font-size: 24px;
}
</style>

自从 Transformer 问世以来，基于注意力机制的语言模型取得了极大的成功。现在的大语言模型，如 GPT、LLaMa、Mistral都是基于 Transformer 架构的。最近有诸多研究工作提出可能可以替代 transformer 架构的新架构。本文整理一下近些年语言模型的变化。

<!-- more -->

# 语言模型

语言模型（language model）是一个对语言的概率模型，首次在八十年代提出。语言模型专注于预测一段文字出现的概率。

$$
P(s) = P(w_{1}, \dots, w_{m}) = \prod_{i}^{m} P(w_i|w_{1},\dots, w_{i-1})
$$

其中 $w_i$ 一般是 token，而一般一个 token 就是一个单词。在以下的讨论中，如果没有特别说明，我默认一个 token 就是一个单词，而一段文字（比如一个句子）的不可分割单元就是一个单词。

换句话说，这个问题可以转化为，给定一个序列 $w_{<t}$，计算下一个单词的概率分布：

$$
P(w_{t}|w_{<t}) \in \mathbb R^V
$$

其中 $V$ 是词表大小，$t$ 是当前要预测的单词的位置。这个目标叫做 next token prediction。

# 语言模型的应用

学习语言的表示，比如词向量（word embeddings），这是假设预测下一个单词所需要的信息可以被利用来完成其他任务。

# 统计语言模型

方法：统计每个序列出现的次数：

$$
P(w_t |w_{<t}) = \frac{ 出现次数 ( w_{<t}, w_t)}{\sum_{w} 出现次数 (w_{<t}, w)} ， \quad w \in V
$$

**问题**：单词的组合数量是 $O(V ^ t)$ 复杂度。

## Word $n$-gram 语言模型

$n$-gram 假设模型假设每个单词出现的概率仅取决于前 $n$ 个单词。可以写成：

$$
P(w_{i} | w_{1}, \dots, w_{i-1}) \approx P(w_{i}|w_{i- 1 (n-1)}, \dots ,w_{i-1})
$$

## Bag-of-Words 模型

假设概率跟顺序无关：

$$
P(w_{i} | w_{1}, \dots, w_{i-1}) \approx P(w_{i})
$$

---

# 深度学习语言模型

# Recurrent Neural Network (RNN)

用一个 hidden state 来保存上下文信息（$w_{<t}$），然后用这个 hidden state 来预测下一个单词。

![Recurrent Neural Network](%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%BF%9B%E5%8C%96/rnn.png)

后面提出的 Long Short-Term Memory (LSTM) 和 Gated Recurrent Unit (GRU) 都是 RNN 的变种，只不过是对输入和 hidden state 的处理方式不同。

两个问题：

- 很难把所有上下文信息都压缩到一个 hidden state 里面。
- 难以并行化：每个 token 对应的 hidden state 都依赖于前一个 token 的 hidden state，所以无法并行计算不同整个序列。

# Transformer: Attention is All You Need

Self-Attention 机制如下。

![Self-attention 机制示意图。](%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%BF%9B%E5%8C%96/self-attention.png)

图中展示输入是 "see that girl run"，然后我们计算 "that" 的潜在表示。

因为右边的向量（hidden representation）不依赖于其他 token 的 hidden representation，所以可以并行计算。

Transformer 模型：

$$
\begin{align*}
X^{(0)} &= \text{Embedding}(s) \in \mathbb R ^{N \times d} \\ 
X^{(l)} &= \text{Attention}\left(X^{(l-1)}\right) \in \mathbb R ^{N \times d} \\
X^{(l)} &= \text{Norm}\left(X^{(l)} + X^{(l-1)}\right) \in \mathbb R ^{N \times d} \\
X^{(l)} &= \text{FFN}\left(X^{(l)}\right) \in \mathbb R ^{N \times d} \\
X^{(l)} &= \text{Norm}\left(X^{(l)} + X^{(l-1)}\right) \in \mathbb R ^{N \times d} \\
\\
\text{Attention}(X) &= \text{softmax}\left(\frac{XW_{q}(XW_{k})^\top}{\sqrt{d}} \right)XW_{v} \\
\end{align*}
$$

其中 $N$ 是序列长度，$d$ 是 hidden size，$s$ 是输入序列，$l$ 是层数，$W_{q}, W_{k}, W_{v}$ 是参数矩阵，$\text{LN}$ 是 layer normalization，$\text{FFN}$ 是一个跟 $t$ 无关的 feed-forward network。

## Attention 的问题

Attention 机制的计算复杂度是 $O(n^2)$。对于训练来说，这一般不是很大的问题。可是在推理的过程中，对于每个 token 都要计算一次 attention，也就是每生成一个 token 的复杂度是 $O(n)$。
